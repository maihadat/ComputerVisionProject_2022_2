{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhQBcSXb297q",
        "outputId": "489255c0-8bf5-4542-da5c-f09222ed84d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Human_Data.zip"
      ],
      "metadata": {
        "id": "DSPBt62IQbWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess\n"
      ],
      "metadata": {
        "id": "IZjIZO66Qo7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data getting"
      ],
      "metadata": {
        "id": "6e_cQ-qXNLZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the data from drive, which was downloaded from OpenImages"
      ],
      "metadata": {
        "id": "tcxRLjiXJ6W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "os.makedirs(\"/content/Data\")\n",
        "def unrar_files():\n",
        "    destination_folder = \"/content/Data\"\n",
        "    for file_name in [\"train.rar\", 'test.rar', 'val.rar']:\n",
        "      unrar_command = f\"unrar x {'/content/drive/MyDrive/CV_Dataset/'+file_name} {destination_folder}\"\n",
        "      subprocess.run(unrar_command, shell=True)\n",
        "\n",
        "unrar_files()"
      ],
      "metadata": {
        "id": "9kFqgVgvTym4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_files(folder_path):\n",
        "    file_list = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if os.path.isfile(os.path.join(folder_path, file_name)):\n",
        "            file_list.append(file_name[:-4])\n",
        "    return file_list"
      ],
      "metadata": {
        "id": "xleAzHd5hJnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take only 1000 images from each test and validation dataset. Take 8000 images from train dataset."
      ],
      "metadata": {
        "id": "LcIbVpmpMf3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file_type in [\"test\", \"val\"]:\n",
        "    files = list_files(\"/content/Data/\"+file_type)\n",
        "    for file_name in files[1000:]:\n",
        "        os.remove(\"/content/Data/\" + file_type + '/' + file_name + '.jpg')\n",
        "files = list_files(\"/content/Data/train\")\n",
        "for file_name in files[8000:]:\n",
        "    os.remove(\"/content/Data/\" + 'train' + '/' + file_name + '.jpg')"
      ],
      "metadata": {
        "id": "4lhvoraeM9oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove unmatch data like image without annotations and otherwise"
      ],
      "metadata": {
        "id": "IbS2vlqLM5ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def data_unite():\n",
        "    for file_type in [\"test\", \"train\", \"val\"]:\n",
        "        files = list_files(\"/content/Data/\"+file_type)\n",
        "        bb_anno =  pd.read_csv('/content/drive/MyDrive/CV_Dataset/Bounding Boxes/'+file_type+'.csv')\n",
        "        image_list = bb_anno[\"ImageID\"].to_list()\n",
        "        for file_name in files:\n",
        "          if file_name not in image_list:\n",
        "            os.remove(\"/content/Data/\" + file_type + '/' + file_name + '.jpg')\n",
        "        tmp = []\n",
        "        files = list_files(\"/content/Data/\"+file_type)\n",
        "        for image in image_list:\n",
        "          if image in files:\n",
        "            tmp.append(image)\n",
        "        df = bb_anno[bb_anno['ImageID'].isin(tmp)]\n",
        "        df.to_csv(\"/content/Data/\"+file_type+\".csv\")\n",
        "\n",
        "\n",
        "data_unite()\n",
        "\n"
      ],
      "metadata": {
        "id": "pB73YPjQf9p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format changing"
      ],
      "metadata": {
        "id": "XApflNg_QwNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We change the format of the annotation data from coco format to Yolo format"
      ],
      "metadata": {
        "id": "RWLPwv6aOgrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "llTBwywAQ0EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_type in ['train', 'test', 'validation']:\n",
        "    dataframe = pd.read_csv(\"/content/\"+file_type+'.csv')\n",
        "    images = dataframe[\"ImageID\"].unique()\n",
        "\n",
        "    for id in images:\n",
        "    # Filter the dataframe based on the ID\n",
        "      filtered_df = dataframe[dataframe['ImageID'] == id]\n",
        "\n",
        "      # Open a text file for writing\n",
        "      filename = \"/content/labels/\" + file_type + f'/{id}.txt'\n",
        "      with open(filename, 'w') as file:\n",
        "          # Iterate over the filtered dataframe rows\n",
        "          for _, row in filtered_df.iterrows():\n",
        "              # Calculate the center, width, and height\n",
        "              x_center = (row['XMin'] + row['XMax']) / 2\n",
        "              y_center = (row['YMin'] + row['YMax']) / 2\n",
        "              width = row['XMax'] - row['XMin']\n",
        "              height = row['YMax'] - row['YMin']\n",
        "\n",
        "              # Write the object information to the text file\n",
        "              file.write(f\"0 {x_center} {y_center} {width} {height}\\n\")"
      ],
      "metadata": {
        "id": "1NL8IHhYR1-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image resizing and normalizing"
      ],
      "metadata": {
        "id": "NEZ5wPslNUyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image size of image data is vary in many size, so we resize the image to 1024x1024, also we normalized the image."
      ],
      "metadata": {
        "id": "0CbocHYWOv4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "files = list_files('/content/Data/test')\n",
        "for file in files:\n",
        "  image = cv2.imread('/content/Data/test/'+file+'.jpg')\n",
        "  print(image.shape)"
      ],
      "metadata": {
        "id": "jGUMSTOIVfum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def resize_and_normalize_image(image_path, output_path, target_size):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Resize the image to the target size\n",
        "    resized_image = cv2.resize(image, target_size)\n",
        "\n",
        "    # Normalize the image (optional)\n",
        "    normalized_image = cv2.normalize(resized_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "\n",
        "    # Remove the old image\n",
        "    os.remove(image_path)\n",
        "\n",
        "    # Store the new image\n",
        "    cv2.imwrite(output_path, normalized_image)\n",
        "\n",
        "for file_type in [\"test\", \"train\", \"val\"]:\n",
        "    files = list_files('/content/Data/'+file_type)\n",
        "    target_size = (1024,1024)\n",
        "    for file in files:\n",
        "        resize_and_normalize_image('/content/Data/'+file_type+'/'+file+'.jpg', '/content/Data/'+file_type+'/'+file+'.jpg', target_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "Zfe2R2N9UBFS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}